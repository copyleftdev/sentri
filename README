# Sentri - High-Performance Microsoft Defender for Identity Discovery Tool

A blazingly fast, modular Rust CLI tool for discovering Microsoft Defender for Identity (MDI) instances across millions of domains with expert-level performance optimizations.

## Features

- **High Performance**: Asynchronous I/O with configurable concurrency limits
- **Rate Limiting**: Built-in rate limiting to respect API boundaries
- **Batch Processing**: Process millions of domains efficiently with chunked processing
- **Intelligent Caching**: In-memory caching with DashMap for repeated queries
- **Error Resilience**: Comprehensive error handling and retry mechanisms
- **Memory Efficient**: Stream processing with controlled memory usage
- **Expert Algorithms**: HTTP/2 connection pooling, DNS caching, and optimized XML parsing

## Performance Optimizations

1. **Connection Pooling**: HTTP/2 with persistent connections and connection reuse
2. **DNS Caching**: Optimized DNS resolver with configurable TTL and cache size
3. **Concurrent Processing**: Tokio-based async processing with semaphore-controlled concurrency
4. **Memory Management**: Streaming file I/O and chunked batch processing
5. **Rate Limiting**: Token bucket algorithm for API rate limiting
6. **Result Caching**: Thread-safe caching with DashMap for repeated domain queries

## Installation

```bash
# Build from source
git clone <repository>
cd sentri
cargo build --release

# The binary will be available at target/release/sentri
```

## Usage

### Single Domain Check

```bash
# Check a single domain
./target/release/sentri single -d example.com

# With custom concurrency and timeout
./target/release/sentri -c 200 -t 10000 single -d example.com
```

### Batch Processing

```bash
# Process domains from file
./target/release/sentri batch -i domains.txt -o results.jsonl

# With custom parameters
./target/release/sentri -c 500 -t 5000 batch \
  -i domains.txt \
  -o results.jsonl \
  --chunk-size 2000 \
  --rate-limit 100
```

### Input File Format

Create a text file with one domain per line:

```
example.com
company.org
test-domain.net
# Comments are ignored
another-domain.com
```

### Output Format

Results are output as JSON Lines format:

```json
{
  "domain": "example.com",
  "tenant": "examplecompany",
  "federated_domains": [
    "example.com",
    "examplecompany.onmicrosoft.com"
  ],
  "mdi_instance": "examplecompanysensorapi.atp.azure.com",
  "processing_time_ms": 234,
  "error": null
}
```

## Performance Tuning

### For Maximum Throughput

```bash
# High concurrency for fast networks
./sentri -c 1000 -t 3000 batch \
  -i large_domain_list.txt \
  -o results.jsonl \
  --chunk-size 5000 \
  --rate-limit 200
```

### For Rate-Limited Scenarios

```bash
# Conservative settings for API limits
./sentri -c 50 -t 10000 batch \
  -i domains.txt \
  -o results.jsonl \
  --chunk-size 500 \
  --rate-limit 10
```

## Architecture

The tool is built with a modular architecture:

- **CLI Module**: Command-line interface and argument parsing
- **Core Module**: Main business logic and orchestration
- **HTTP Module**: Optimized HTTP client with connection pooling
- **DNS Module**: High-performance DNS resolver with caching
- **XML Module**: Fast XML parsing for SOAP responses

## Performance Benchmarks

On a modern system with good network connectivity:

- **Single Domain**: ~200ms average response time
- **Batch Processing**: 100-500 domains/second (depending on network and rate limits)
- **Memory Usage**: <50MB for processing millions of domains
- **Concurrency**: Scales efficiently up to 1000+ concurrent requests

## Environment Variables

```bash
# Enable debug logging
RUST_LOG=debug ./sentri single -d example.com

# Enable trace logging for detailed debugging
RUST_LOG=trace ./sentri batch -i domains.txt
```

## Error Handling

The tool provides comprehensive error handling:

- **Network Errors**: Automatic retries with exponential backoff
- **DNS Failures**: Graceful handling of non-existent domains
- **Rate Limiting**: Built-in respect for API rate limits
- **Malformed Responses**: Robust XML parsing with error recovery
- **File I/O Errors**: Clear error messages for file operations

## Configuration Examples

### High-Volume Processing (Millions of Domains)

```bash
# Process 10M domains with optimal settings
./sentri -c 800 -t 4000 batch \
  -i ten_million_domains.txt \
  -o results.jsonl \
  --chunk-size 10000 \
  --rate-limit 300
```

### Memory-Constrained Environment

```bash
# Lower memory usage with smaller chunks
./sentri -c 100 -t 8000 batch \
  -i domains.txt \
  -o results.jsonl \
  --chunk-size 100 \
  --rate-limit 50
```

### Network-Constrained Environment

```bash
# Conservative settings for slow networks
./sentri -c 20 -t 15000 batch \
  -i domains.txt \
  -o results.jsonl \
  --chunk-size 50 \
  --rate-limit 5
```

## Advanced Features

### Result Caching
- Automatic caching of successful domain checks
- Thread-safe concurrent access with DashMap
- Reduces redundant API calls for repeated domains

### Streaming Processing
- Processes files larger than available RAM
- Constant memory usage regardless of input size
- Real-time result output

### Connection Optimization
- HTTP/2 multiplexing for reduced latency
- Keep-alive connections with connection pooling
- Automatic connection management

## Monitoring and Observability

The tool provides detailed logging at multiple levels:

```bash
# Info level (default)
RUST_LOG=info ./sentri batch -i domains.txt

# Debug level for troubleshooting
RUST_LOG=debug ./sentri batch -i domains.txt

# Trace level for detailed analysis
RUST_LOG=trace ./sentri batch -i domains.txt
```

Log output includes:
- Processing statistics
- Network performance metrics
- Error details and retry attempts
- Cache hit rates
- Processing time per domain

## Development

### Building for Production

```bash
# Optimized release build
cargo build --release

# With additional optimizations
RUSTFLAGS="-C target-cpu=native" cargo build --release
```

### Running Tests

```bash
# Run all tests
cargo test

# Run with logging
RUST_LOG=debug cargo test

# Performance benchmarks
cargo bench
```

### Code Organization

```
src/
├── main.rs          # Application entry point
├── cli.rs           # Command-line interface
├── core.rs          # Core business logic
├── http.rs          # HTTP client implementation
├── dns.rs           # DNS resolver
└── xml.rs           # XML parsing
```

## Dependencies

Core dependencies chosen for performance and reliability:

- **tokio**: Async runtime with excellent performance
- **reqwest**: HTTP client with HTTP/2 support
- **trust-dns-resolver**: High-performance DNS resolver
- **quick-xml**: Fast XML parsing
- **dashmap**: Concurrent hashmap for caching
- **clap**: Modern CLI parsing
- **anyhow**: Error handling

## Security Considerations

- No credentials stored or transmitted
- Uses Microsoft's public autodiscover endpoints
- Respects rate limits to avoid overwhelming services
- Minimal network footprint with connection reuse

## Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Ensure all tests pass
5. Submit a pull request

## License

MIT License - see LICENSE file for details.